{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i2.wp.com/abcsofliteracy.com/wp-content/uploads/2020/02/LN8.jpg\" data-canonical-src=\"https://i2.wp.com/abcsofliteracy.com/wp-content/uploads/2020/02/LN8.jpg\" width=\"400\" height=\"100\" />\n",
    "\n",
    "\n",
    "##  Data    \n",
    "<a href=\"https://www.kaggle.com/datasets/nishan192/letterrecognition-using-svm\">Kaggle</a>\n",
    "    \n",
    "\n",
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "* Use <a href=\"https://snapml.readthedocs.io/en/latest/decision_trees.html\">IBM snapML</a> algorithms to classify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Additional Information**\n",
    "\n",
    "The objective is to identify each of a large number of black-and-white rectangular pixel displays as one of the 26 capital letters in the English alphabet.  The character images were based on 20 different fonts and each letter within these 20 fonts was randomly distorted to produce a file of 20,000 unique stimuli.  Each stimulus was converted into 16 primitive numerical attributes (statistical moments and edge counts) which were then scaled to fit into a range of integer values from 0 through 15.  We typically train on the first 16000 items and then use the resulting model to predict the letter category for the remaining 4000.  See the article cited above for more details.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of contents</h1>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ol>\n",
    "        <li><a href=\"#load_dataset\">Load the  data</a></li>\n",
    "        <li><a href=\"#modeling\">Modeling</a></li>\n",
    "        <li><a href=\"#evaluation\">Evaluation</a></li>\n",
    "        <li><a href=\"#practice\">Practice</a></li>\n",
    "    </ol>\n",
    "</div>\n",
    "<br>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install snapml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.optimize as opt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dealing with imbalance classes\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "import pickle # save the model\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Load Data From CSV File  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  letter  xbox   ybox   width   height  onpix   xbar   ybar   x2bar  y2bar   \\\n",
       "0      T      2      8       3       5       1      8     13      0       6   \n",
       "1      I      5     12       3       7       2     10      5      5       4   \n",
       "2      D      4     11       6       8       6     10      6      2       6   \n",
       "3      N      7     11       6       6       3      5      9      4       6   \n",
       "4      G      2      1       3       1       1      8      6      6       6   \n",
       "\n",
       "   xybar   x2ybar  xy2bar  xedge   xedgey  yedge   yedgex  \n",
       "0       6      10       8       0       8       0       8  \n",
       "1      13       3       9       2       8       4      10  \n",
       "2      10       3       7       3       7       3       9  \n",
       "3       4       4      10       6      10       2       8  \n",
       "4       6       5       9       1       7       5      10  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_recognition = pd.read_csv(\"letter-recognition.csv\")\n",
    "letter_recognition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['letter', 'xbox ', 'ybox ', 'width ', 'height', 'onpix ', 'xbar ',\n",
       "       'ybar ', 'x2bar', 'y2bar ', 'xybar ', 'x2ybar', 'xy2bar', 'xedge ',\n",
       "       'xedgey', 'yedge ', 'yedgex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the columns\n",
    "letter_recognition.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    object\n",
       "xbox       int64\n",
       "ybox       int64\n",
       "width      int64\n",
       "height     int64\n",
       "onpix      int64\n",
       "xbar       int64\n",
       "ybar       int64\n",
       "x2bar      int64\n",
       "y2bar      int64\n",
       "xybar      int64\n",
       "x2ybar     int64\n",
       "xy2bar     int64\n",
       "xedge      int64\n",
       "xedgey     int64\n",
       "yedge      int64\n",
       "yedgex     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data types\n",
    "letter_recognition.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    0\n",
       "xbox      0\n",
       "ybox      0\n",
       "width     0\n",
       "height    0\n",
       "onpix     0\n",
       "xbar      0\n",
       "ybar      0\n",
       "x2bar     0\n",
       "y2bar     0\n",
       "xybar     0\n",
       "x2ybar    0\n",
       "xy2bar    0\n",
       "xedge     0\n",
       "xedgey    0\n",
       "yedge     0\n",
       "yedgex    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "letter_recognition.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "U    813\n",
       "D    805\n",
       "P    803\n",
       "T    796\n",
       "M    792\n",
       "A    789\n",
       "X    787\n",
       "Y    786\n",
       "N    783\n",
       "Q    783\n",
       "F    775\n",
       "G    773\n",
       "E    768\n",
       "B    766\n",
       "V    764\n",
       "L    761\n",
       "R    758\n",
       "I    755\n",
       "O    753\n",
       "W    752\n",
       "S    748\n",
       "J    747\n",
       "K    739\n",
       "C    736\n",
       "H    734\n",
       "Z    734\n",
       "Name: letter, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value count of the churn to see if we are dealing with a balanced or unbalanced dataset\n",
    "letter_recognition['letter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique letters\n",
    "letter_recognition['letter'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing and selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  8,  3,  5,  1,  8, 13,  0,  6,  6, 10,  8,  0,  8,  0,  8],\n",
       "       [ 5, 12,  3,  7,  2, 10,  5,  5,  4, 13,  3,  9,  2,  8,  4, 10],\n",
       "       [ 4, 11,  6,  8,  6, 10,  6,  2,  6, 10,  3,  7,  3,  7,  3,  9],\n",
       "       [ 7, 11,  6,  6,  3,  5,  9,  4,  6,  4,  4, 10,  6, 10,  2,  8],\n",
       "       [ 2,  1,  3,  1,  1,  8,  6,  6,  6,  6,  5,  9,  1,  7,  5, 10]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = letter_recognition[['xbox ', 'ybox ', 'width ', 'height', 'onpix ', 'xbar ',\n",
    "       'ybar ', 'x2bar', 'y2bar ', 'xybar ', 'x2ybar', 'xy2bar', 'xedge ',\n",
    "       'xedgey', 'yedge ', 'yedgex']]\n",
    "X = np.asarray(feature_df)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['T', 'I', 'D', 'N', 'G'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encode the column\n",
    "#from sklearn import preprocessing\n",
    "#le = preprocessing.LabelEncoder()\n",
    "#letter_recognition['letter'] = le.fit_transform(letter_recognition['letter'])\n",
    "\n",
    "# assign to the y variable\n",
    "y = np.asarray(letter_recognition['letter'])\n",
    "y [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our dataset into train and test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (16000, 16) (16000,)\n",
      "Test set: (4000, 16) (4000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=10, stratify=y)\n",
    "print ('Train set:', x_train.shape,  y_train.shape)\n",
    "print ('Test set:', x_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # scaler objecy\n",
    "x_train = scaler.fit_transform(x_train) # allow the scaler object to learn the features and transform the training data\n",
    "x_test =  scaler.transform(x_test) # apply the learned features on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.02959671,  1.19334262,  1.42594162,  1.16054883,  0.68065974,\n",
       "        -0.44200536, -0.64837588,  0.50794596,  0.76222057, -0.91637373,\n",
       "        -0.17079137,  0.03726837, -0.01976787, -0.2197797 ,  0.12067208,\n",
       "        -0.4938846 ],\n",
       "       [-0.53682618, -0.61529462, -0.06109231,  1.16054883,  1.59437363,\n",
       "         1.52396467,  1.07395245, -0.23206181, -1.3432157 , -1.71893433,\n",
       "         0.58670327,  0.5181505 ,  0.40764556,  3.00397826,  0.90045934,\n",
       "         0.12366413]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaled x_train\n",
    "x_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05896714, -1.82105279, -1.05244827, -1.49055617, -0.68991109,\n",
       "         0.54097966, -0.2177938 ,  0.87794985,  0.76222057, -0.51509343,\n",
       "         0.20795595, -1.88626016, -0.4471813 , -0.2197797 , -0.26922155,\n",
       "        -1.11143334],\n",
       "       [ 2.07387863,  0.289024  ,  0.43458567,  2.48610134,  0.68065974,\n",
       "         0.04948715, -0.2177938 , -0.23206181, -0.92212845,  1.09002778,\n",
       "        -0.17079137,  0.03726837, -0.01976787,  0.42497189,  2.8499275 ,\n",
       "        -1.11143334]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaled x_test\n",
    "x_test[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"svm_snap\">\n",
    "    <h2>Build a RandomForest model with Snap ML</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 359 ms\n",
      "Wall time: 476 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import the RandomForest from Snap ML\n",
    "from snapml import RandomForestClassifier as SnapForest\n",
    "\n",
    "# in contrast to scikit-learn's LinearSVC, Snap ML offers multi-threaded CPU/GPU training of RandomForest\n",
    "# to use the GPU, set the use_gpu parameter to True\n",
    "# rf = SnapForest(class_weight='balanced', random_state=25, use_gpu=True, fit_intercept=False)\n",
    "\n",
    "# to set the number of threads used at training time, one needs to set the n_jobs parameter\n",
    "rf = SnapForest(n_estimators=10, criterion='gini', \n",
    "                            max_depth=20, min_samples_leaf=1, \n",
    "                            max_features='auto', bootstrap=True, \n",
    "                            n_jobs=1, random_state=None, verbose=False, \n",
    "                            use_histograms=False, hist_nbins=256, \n",
    "                            use_gpu=False, gpu_ids=[0], \n",
    "                            compress_trees=False)\n",
    "\n",
    "# train an SVM model using Snap ML\n",
    "clf = rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After being fitted, the model can then be used to predict new values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D', 'Z', 'E', 'Z', 'F'], dtype='<U32')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = clf.predict(x_test)\n",
    "yhat[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg F1-score: 0.9388\n",
      "Accuracy: 0.9387\n"
     ]
    }
   ],
   "source": [
    "Random_f1 = f1_score(y_test, yhat, average='weighted')\n",
    "Random_accuracy = accuracy_score(y_test, yhat)\n",
    "\n",
    "print(\"Avg F1-score: %.4f\" % Random_f1)\n",
    "print(\"Accuracy: %.4f\" % Random_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Save the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "pickle.dump(clf, open('letter-recognition-RF(SnapML).pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"evaluation\">Evaluation</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.97      0.97       158\n",
      "           B       0.84      0.95      0.89       153\n",
      "           C       0.96      0.93      0.94       147\n",
      "           D       0.89      0.92      0.91       161\n",
      "           E       0.93      0.90      0.91       154\n",
      "           F       0.89      0.90      0.89       155\n",
      "           G       0.92      0.95      0.93       155\n",
      "           H       0.92      0.81      0.86       147\n",
      "           I       0.95      0.96      0.96       151\n",
      "           J       1.00      0.93      0.97       149\n",
      "           K       0.94      0.92      0.93       148\n",
      "           L       0.99      0.95      0.97       152\n",
      "           M       0.96      0.96      0.96       158\n",
      "           N       0.94      0.98      0.96       157\n",
      "           O       0.89      0.90      0.90       151\n",
      "           P       0.97      0.91      0.94       161\n",
      "           Q       0.91      0.95      0.93       157\n",
      "           R       0.89      0.93      0.91       151\n",
      "           S       0.92      0.94      0.93       149\n",
      "           T       0.95      0.99      0.97       159\n",
      "           U       0.97      0.94      0.95       163\n",
      "           V       0.96      0.97      0.97       153\n",
      "           W       0.99      0.97      0.98       150\n",
      "           X       0.96      0.96      0.96       157\n",
      "           Y       0.96      0.96      0.96       157\n",
      "           Z       0.97      0.97      0.97       147\n",
      "\n",
      "    accuracy                           0.94      4000\n",
      "   macro avg       0.94      0.94      0.94      4000\n",
      "weighted avg       0.94      0.94      0.94      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print (classification_report(y_test, yhat,labels=np.unique(yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Boosting Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 3s\n",
      "Wall time: 4min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import the BoostingMachineClassifier from Snap ML\n",
    "from snapml import BoostingMachineClassifier as BoostMachine\n",
    "\n",
    "Booting_clf = BoostMachine(n_jobs=1, num_round=100, max_depth=15, \n",
    "                                 min_max_depth=1, max_max_depth=5, early_stopping_rounds=10, \n",
    "                                 random_state=0, base_score=None, learning_rate=0.1, verbose=False, \n",
    "                                 compress_trees=False, class_weight=None, use_histograms=True, \n",
    "                                 hist_nbins=256, use_gpu=False, gpu_ids=[0], colsample_bytree=1.0,\n",
    "                                 subsample=1.0, lambda_l2=0.0, \n",
    "                                 tree_select_probability=1.0, regularizer=1.0,\n",
    "                                 fit_intercept=False, gamma=1.0, n_components=10)\n",
    "\n",
    "\n",
    "Booting_clf.fit(x_train, y_train) \n",
    "yhat = Booting_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg F1-score: 0.9352\n",
      "Accuracy: 0.9353\n"
     ]
    }
   ],
   "source": [
    "# print the F1-score and accuracy\n",
    "Boosting_f1 = f1_score(y_test, yhat, average='weighted')\n",
    "Boosting_accuracy = accuracy_score(y_test, yhat)\n",
    "\n",
    "print(\"Avg F1-score: %.4f\" % Boosting_f1)\n",
    "print(\"Accuracy: %.4f\" % Boosting_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Booting_clf, open('letter-recognition-Boosting_Machine(SnapML).pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.97      0.97       158\n",
      "           B       0.84      0.95      0.89       153\n",
      "           C       0.96      0.93      0.94       147\n",
      "           D       0.89      0.92      0.91       161\n",
      "           E       0.93      0.90      0.91       154\n",
      "           F       0.89      0.90      0.89       155\n",
      "           G       0.92      0.95      0.93       155\n",
      "           H       0.92      0.81      0.86       147\n",
      "           I       0.95      0.96      0.96       151\n",
      "           J       1.00      0.93      0.97       149\n",
      "           K       0.94      0.92      0.93       148\n",
      "           L       0.99      0.95      0.97       152\n",
      "           M       0.96      0.96      0.96       158\n",
      "           N       0.94      0.98      0.96       157\n",
      "           O       0.89      0.90      0.90       151\n",
      "           P       0.97      0.91      0.94       161\n",
      "           Q       0.91      0.95      0.93       157\n",
      "           R       0.89      0.93      0.91       151\n",
      "           S       0.92      0.94      0.93       149\n",
      "           T       0.95      0.99      0.97       159\n",
      "           U       0.97      0.94      0.95       163\n",
      "           V       0.96      0.97      0.97       153\n",
      "           W       0.99      0.97      0.98       150\n",
      "           X       0.96      0.96      0.96       157\n",
      "           Y       0.96      0.96      0.96       157\n",
      "           Z       0.97      0.97      0.97       147\n",
      "\n",
      "    accuracy                           0.94      4000\n",
      "   macro avg       0.94      0.94      0.94      4000\n",
      "weighted avg       0.94      0.94      0.94      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print (classification_report(y_test, yhat,labels=np.unique(yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = {\n",
    "  \"Accuracy\": [Random_f1, Boosting_f1],\n",
    "  \"F1 score\" : [Random_accuracy, Boosting_accuracy],\n",
    "}\n",
    "\n",
    "\n",
    "Report = pd.DataFrame(metric)\n",
    "Report = Report.rename(index={ 0:'Random Forest-SnapML', 1:'Boosting Machine - SnapML'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest-SnapML</th>\n",
       "      <td>0.938810</td>\n",
       "      <td>0.93875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boosting Machine - SnapML</th>\n",
       "      <td>0.935217</td>\n",
       "      <td>0.93525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy  F1 score\n",
       "Random Forest-SnapML       0.938810   0.93875\n",
       "Boosting Machine - SnapML  0.935217   0.93525"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this lab!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
